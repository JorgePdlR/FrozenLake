{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-15T22:40:27.325110600Z",
     "start_time": "2023-12-15T22:40:27.312120100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We have 17 * 17 * 4 shape of the matrix, absorving state is the last one\n",
    "# This means that we can move betweeen the 16 states, and wwe can transition to the absorbing state that is 17\n",
    "# next_state, state, action\n",
    "lake_p = np.load(\"p.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import contextlib\n",
    "\n",
    "# Configures numpy print options\n",
    "@contextlib.contextmanager\n",
    "def _printoptions(*args, **kwargs):\n",
    "    original = np.get_printoptions()\n",
    "    np.set_printoptions(*args, **kwargs)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        np.set_printoptions(**original)\n",
    "\n",
    "\n",
    "class EnvironmentModel:\n",
    "    def __init__(self, n_states, n_actions, seed=None):\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.random_state = np.random.RandomState(seed)\n",
    "\n",
    "    def p(self, next_state, state, action):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def r(self, next_state, state, action):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def draw(self, state, action):\n",
    "        p = [self.p(ns, state, action) for ns in range(self.n_states)]\n",
    "        next_state = self.random_state.choice(self.n_states, p=p)\n",
    "        reward = self.r(next_state, state, action)\n",
    "\n",
    "        return next_state, reward\n",
    "\n",
    "\n",
    "class Environment(EnvironmentModel):\n",
    "    def __init__(self, n_states, n_actions, max_steps, pi, seed=None):\n",
    "        EnvironmentModel.__init__(self, n_states, n_actions, seed)\n",
    "\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        self.pi = pi\n",
    "        if self.pi is None:\n",
    "            self.pi = np.full(n_states, 1. /n_states)\n",
    "\n",
    "    def reset(self):\n",
    "        self.n_steps = 0\n",
    "        self.state = self.random_state.choice(self.n_states, p=self.pi)\n",
    "\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        if action < 0 or action >= self.n_actions:\n",
    "            raise Exception('Invalid action.')\n",
    "\n",
    "        self.n_steps += 1\n",
    "        done = (self.n_steps >= self.max_steps)\n",
    "\n",
    "        self.state, reward = self.draw(self.state, action)\n",
    "\n",
    "        return self.state, reward, done\n",
    "\n",
    "    def render(self, policy=None, value=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class FrozenLake(Environment):\n",
    "    def __init__(self, lake, slip, max_steps, seed=None):\n",
    "        \"\"\"\n",
    "        lake: A matrix that represents the lake. For example:\n",
    "        lake =  [['&', '.', '.', '.'],\n",
    "                ['.', '#', '.', '#'],\n",
    "                ['.', '.', '.', '#'],\n",
    "                ['#', '.', '.', '$']]\n",
    "        slip: The probability that the agent will slip\n",
    "        max_steps: The maximum number of time steps in an episode\n",
    "        seed: A seed to control the random number generator (optional)\n",
    "        \"\"\"\n",
    "        # start (&), frozen (.), hole (#), goal ($)\n",
    "        self.lake = np.array(lake)\n",
    "        self.lake_flat = self.lake.reshape(-1)\n",
    "\n",
    "        self.slip = slip\n",
    "\n",
    "        n_states = self.lake.size + 1\n",
    "        n_actions = 4\n",
    "\n",
    "        pi = np.zeros(n_states, dtype=float)\n",
    "        pi[np.where(self.lake_flat == '&')[0]] = 1.0\n",
    "\n",
    "        self.absorbing_state = n_states - 1\n",
    "\n",
    "        # TODO: ?? Not sure what goes here\n",
    "\n",
    "        Environment.__init__(self, n_states, n_actions, max_steps, pi, seed=seed)\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done = Environment.step(self, action)\n",
    "\n",
    "        done = (state == self.absorbing_state) or done\n",
    "\n",
    "        return state, reward, done\n",
    "\n",
    "    def p(self, next_state, state, action):\n",
    "        # Convert possible actions to directions for clarity of reading the code:\n",
    "        up, left, down, right = [0, 1, 2, 3]\n",
    "        # Probability of transitioning from state to next_state given an action\n",
    "        # (return value)\n",
    "        pt = 0.0\n",
    "        \n",
    "        \n",
    "        # 1. If the agent is in the absorbing state the probability of remaining in \n",
    "        #    the same place is 1. Any action taken in the absorbing state leads\n",
    "        #    to the absorbing state. Validating this first to avoid dealing with\n",
    "        #    'out of index' issues with the self.lake_flat array since the\n",
    "        #    absorbing state is in the self.lake.size + 1 position\n",
    "        if state == self.absorbing_state and next_state == self.absorbing_state:\n",
    "            # Assigning return value to pt just to keep the convention that pt\n",
    "            # is the return value. Same convention is used in the rest of the\n",
    "            # function.\n",
    "            pt = 1.0\n",
    "            return pt\n",
    "        elif state == self.absorbing_state:\n",
    "            return pt\n",
    "   \n",
    "        # Is the agent in a hole or the goal ?\n",
    "        hole_or_goal = True if self.lake_flat[state] == '#' or self.lake_flat[state] == '$' else False\n",
    "\n",
    "\n",
    "        # 2. If the agent is in a hole or in the goal the probability of moving to \n",
    "        #    the absorbing state is 1.\n",
    "        if hole_or_goal and next_state == self.absorbing_state:\n",
    "            pt = 1.0\n",
    "            return pt\n",
    "        # If the agent is in any position different from a hole or the goal, and it\n",
    "        # wants to move to the absorbing state the probability is 0, or if it is\n",
    "        # in a hole or the goal, and it tries to move to any other state different\n",
    "        # from the absorbing state the probability is 0. \n",
    "        elif next_state == self.absorbing_state or hole_or_goal:\n",
    "            return pt\n",
    "        \n",
    "        \n",
    "        # 3. Validate if the agent can move from the current state to the next_state.\n",
    "        #    Consider that it has 4 possible actions: up, down, left, right;\n",
    "        #    this means that it can move in just 1 direction per action, either\n",
    "        #    x or y. The absolute change in the coordinates x, y from state to\n",
    "        #    next_state can't be grater than 1\n",
    "        \n",
    "        # Get x, y coordinates of state and next_state \n",
    "        next_state_y, next_state_x = np.unravel_index(next_state, self.lake.shape)\n",
    "        state_y, state_x = np.unravel_index(state, self.lake.shape)\n",
    "        # A negative delta_x indicates that the agent should move to the left,\n",
    "        # positive delta_x indicates it should move to the right\n",
    "        delta_x = next_state_x - state_x\n",
    "        # A negative delta_y indicates that the agent should go down, positive\n",
    "        # delta_y indicate it should go up\n",
    "        delta_y = next_state_y - state_y\n",
    "\n",
    "        # Probability of making an invalid move is 0\n",
    "        if (np.abs(delta_x) + np.abs(delta_y)) > 1 and not hole_or_goal:\n",
    "            return pt\n",
    "        \n",
    "        \n",
    "        # 4. Given that the transition from state to next_state is valid, validate\n",
    "        #    that by executing the action the agent can get from state to\n",
    "        #    next_state either by the selected action or by slipping.\n",
    "        \n",
    "        # Borders of the lake \n",
    "        border_y, border_x = self.lake.shape\n",
    "        border_x -= 1\n",
    "        border_y -= 1\n",
    "        \n",
    "        # Defining walls as the number of borders each tile collides with.\n",
    "        # Get walls in x and y\n",
    "        walls_y = 1 if state_y == border_y or state_y == 0 else 0\n",
    "        walls_x = 1 if state_x == border_x or state_x == 0 else 0\n",
    "        # Add the number of walls this state collides with x and y\n",
    "        walls   = walls_y + walls_x\n",
    "        \n",
    "        # Transition is from state to next_state, where state is not equal to \n",
    "        # next_state. In other words, the agent is trying to move from the\n",
    "        # current state\n",
    "        if delta_x or delta_y:\n",
    "            # For transitioning from state to the next_state the action provided\n",
    "            # is the correct one. The agent will get to the next state unless it slips\n",
    "            if ((delta_x > 0 and action == right) or (delta_x < 0 and action == left) or\n",
    "                (delta_y > 0 and action == down) or (delta_y < 0 and action == up)):\n",
    "                pt = (1 - self.slip) + (self.slip / self.n_actions)\n",
    "            # For transitioning from state to the next_state the action provided\n",
    "            # is incorrect. The only wat to transition is by slipping. \n",
    "            else:\n",
    "                pt = (self.slip / self.n_actions)\n",
    "        # Transition is to the same state: state == next_state. The agent can remain in \n",
    "        # the same state if it crashes with a wall. The number of walls contribute \n",
    "        # to how probable is to remain in the same state.\n",
    "        elif walls:\n",
    "            # The agent is moving to a wall, it will remain in the same state unless is\n",
    "            # slips to a place without a wall.\n",
    "            if (action == left and state_x == 0) or (action == right and state_x == border_x) or \\\n",
    "               (action == up and state_y == 0) or (action == down and state_y == border_y):\n",
    "                pt = (1 - self.slip) + ((self.slip / self.n_actions) * walls)\n",
    "            # Action is not in a direction of a wall, the agent will remain in the same\n",
    "            # state just if it slips into a wall\n",
    "            else:\n",
    "                pt = (self.slip / self.n_actions) * walls\n",
    "        # Is not necessary to put an else case here, since pt was initialized to 0.0\n",
    "        # If pt has a value of 0.0 at this point means that the agent wanted to remain\n",
    "        # in the same state but there are no walls to crash to remain in the same place. \n",
    "        # So the probability of remaining in the same place is 0 given any action,\n",
    "        # even if the agent slips it will end up moving. \n",
    "                \n",
    "        # Return the probability of moving from state to next_state given an action and\n",
    "        # the probability of slipping\n",
    "        return pt\n",
    "\n",
    "    def r(self, next_state, state, action):\n",
    "        # Reward received by transitioning from state to next_state \n",
    "        # given an action\n",
    "        reward = 0.0\n",
    "        \n",
    "        # The agent receives a reward of 1 upon taking an action in the goal\n",
    "        if state != self.absorbing_state and self.lake_flat[state] == '$':\n",
    "            reward = 1.0\n",
    "    \n",
    "        # In any other case there is no reward\n",
    "        return reward    \n",
    "\n",
    "    def render(self, policy=None, value=None):\n",
    "        if policy is None:\n",
    "            lake = np.array(self.lake_flat)\n",
    "\n",
    "            if self.state < self.absorbing_state:\n",
    "                lake[self.state] = '@'\n",
    "\n",
    "            print(lake.reshape(self.lake.shape))\n",
    "        else:\n",
    "            # UTF-8 arrows look nicer, but cannot be used in LaTeX\n",
    "            # https://www.w3schools.com/charsets/ref_utf_arrows.asp\n",
    "            actions = ['^', '<', '_', '>']\n",
    "\n",
    "            print('Lake:')\n",
    "            print(self.lake)\n",
    "\n",
    "            print('Policy:')\n",
    "            policy = np.array([actions[a] for a in policy[:-1]])\n",
    "            print(policy.reshape(self.lake.shape))\n",
    "\n",
    "            print('Value:')\n",
    "            with _printoptions(precision=3, suppress=True):\n",
    "                print(value[:-1].reshape(self.lake.shape))\n",
    "\n",
    "def play(env):\n",
    "    actions = ['w', 'a', 's', 'd']\n",
    "\n",
    "    state = env.reset()\n",
    "    env.render()\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        c = input('\\nMove: ')\n",
    "        if c not in actions:\n",
    "            raise Exception('Invalid action')\n",
    "\n",
    "        state, r, done = env.step(actions.index(c))\n",
    "\n",
    "        env.render()\n",
    "        print('Reward: {0}.'.format(r))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T23:42:14.395948800Z",
     "start_time": "2023-12-16T23:42:14.352899400Z"
    }
   },
   "id": "c6527c42d481d7df"
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Small frozen lake array\n",
    "lake =  [['&', '.', '.', '.'],\n",
    "        ['.', '#', '.', '#'],\n",
    "        ['.', '.', '.', '#'],\n",
    "        ['#', '.', '.', '$']]\n",
    "\n",
    "# Create small frozen lake environment\n",
    "ffl = FrozenLake(lake=lake, slip=.1, max_steps=10, seed=None)\n",
    "\n",
    "# Create an array of transitioning to all the states given all\n",
    "# the actions in the lake. Using this array to compare it to the\n",
    "# one provided in the assignment that was loaded at the begining\n",
    "# of this document \n",
    "probb = list()\n",
    "for nextState in range (ffl.n_states):\n",
    "    for sttate in range (ffl.n_states):\n",
    "        for act in range (ffl.n_actions):\n",
    "            probb.append((ffl.p(nextState, sttate, act)))\n",
    "\n",
    "# Convert list to numpy array\n",
    "probb = np.array(probb)\n",
    "# Give correct shape, trusting in reshapes black magic\n",
    "probb = probb.reshape(17, 17, 4)\n",
    "\n",
    "# Validate that the array is the same\n",
    "equal = probb == lake_p\n",
    "# If there is no False, means that all probabilities match\n",
    "# with the probabilities given in the assignment.\n",
    "print(np.where(equal == False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T23:42:14.974244600Z",
     "start_time": "2023-12-16T23:42:14.949687100Z"
    }
   },
   "id": "1c3d7ed2c316b52d"
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(lake_p[16][15])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T23:42:47.361806900Z",
     "start_time": "2023-12-16T23:42:47.316502900Z"
    }
   },
   "id": "a4cc4f3e5969c"
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T23:11:16.825374400Z",
     "start_time": "2023-12-16T23:11:16.810387800Z"
    }
   },
   "id": "590e6f6c1b504cb2"
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T23:11:17.095273400Z",
     "start_time": "2023-12-16T23:11:17.057838400Z"
    }
   },
   "id": "84fbc3881304a3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ead7e60b86563f50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
